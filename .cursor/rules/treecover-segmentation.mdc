---
description: Working with `processor/src/treecover_segmentation/predict_treecover.py` - Running segmentation inference or pipelines
alwaysApply: false
---
# Treecover Segmentation

## WHEN TO USE
- Working with `processor/src/treecover_segmentation/predict_treecover.py`
- Running segmentation inference or pipelines

## Key Files
- `processor/src/process_treecover_segmentation.py` - Entry point
- `processor/src/treecover_segmentation/predict_treecover.py` - Main inference
- `processor/src/treecover_segmentation/predict_pipeline.py` - Pipeline logic
- Config: `processor/src/treecover_segmentation/treecover_inference_config.json`
- Models: `assets/models/segformer_b5_full_epoch_100.safetensors`

## Requirements
- GPU required; assume CUDA-capable environment
- Ensure model files are present (`make download-assets`)
- Docker socket for TCD container execution

## Data Flow Pattern (Named Volumes - Same as ODM)
1. Processor SSH pulls orthomosaic from storage server
2. Reproject to EPSG:3395 (World Mercator) for TCD
3. Creates named Docker volume: `tcd_volume_{dataset_id}`
4. Copies reprojected ortho to volume via temp Alpine container
5. Runs TCD container with volume mounted at `/tcd_data`
6. TCD writes confidence map to volume
7. **Extract confidence map from volume** (tar streaming)
8. Postprocess: threshold, convert to polygons
9. Save results to database via labels system
10. Cleanup volume and temp containers

**Why Named Volumes?**
- Same reason as ODM - machine separation in production
- No shared filesystem between API and Processor servers
- Avoids permission issues

## Patterns
- Use functions (no classes) for pipeline steps
- Read/write via `settings`-derived paths
- Keep memory usage bounded (tile-wise inference if needed)
- Uses same named volume pattern as ODM (machine separation)

## Failure Modes
- Missing model/checkpoint → verify assets path
- CRS/transform mismatches → ensure GeoTIFF standardized (`standardise_geotiff.py`)
- CUDA OOM → reduce tile size/batch size
- **Memory exhaustion during extraction** (tar streaming bug - see below)
- Zombie TCD extract containers stuck running

## Known Bug: Tar Extraction Memory Issue
**Location:** `processor/src/treecover_segmentation/predict_treecover.py:354`

**Same bug as ODM:**
```python
# BROKEN - loads entire confidence map into RAM!
with tarfile.open(mode='r|', fileobj=io.BytesIO(b''.join(archive_stream))) as tar:
    tar.extractall(local_output_dir)
```

**Fix:** Same as ODM - stream directly without loading
```python
with tarfile.open(mode='r|*', fileobj=archive_stream) as tar:
    for member in tar:
        tar.extract(member, local_output_dir)
```

## Debugging
- Run processor tests targeting treecover modules
- Log intermediate shapes and CRS when investigating errors
- If behavior is unclear, ask for expected output contract
- See `deployment-architecture.mdc` for full architecture context
