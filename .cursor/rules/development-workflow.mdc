---
alwaysApply: true
---
# Development Workflow & Testing

## üìã **WHEN TO USE THIS RULE**
**Agent should request this rule when:**
- Setting up or managing development environment
- Running tests or debugging test failures
- Working with CLI commands or container orchestration
- Troubleshooting development environment issues
- Implementing real data testing patterns

## üéØ **CORE PRINCIPLES**
**ALWAYS use `deadtrees` CLI commands. NEVER run pytest directly - always use `deadtrees dev test` commands.**
**Use real data and fixtures instead of mocking for geospatial and utility functions.**
**PREFER FUNCTIONAL PROGRAMMING over classes throughout the codebase.**

## üö® **FUNCTIONAL PROGRAMMING REQUIREMENTS**

### **‚ùå NEVER Use Test Classes**
```python
# BAD: Test classes are not allowed
class TestUploadFunctionality:
    def test_upload_zip_processing(self):
        pass
    
    def test_upload_geotiff_processing(self):
        pass

# GOOD: Use functions instead
def test_upload_zip_processing():
    """Test ZIP upload processing functionality"""
    pass

def test_upload_geotiff_processing():
    """Test GeoTIFF upload processing functionality"""
    pass
```

### **‚úÖ Functional Test Structure (Required Pattern)**
```python
# Always use function-based tests with descriptive names
def test_process_raw_images_upload_creates_dataset(temp_test_zip, test_user, auth_token):
    """Test that ZIP upload creates v2_datasets entry correctly"""
    dataset = await process_raw_images_upload(
        user_id=test_user,
        file_path=temp_test_zip,
        file_name='test_minimal_3_images.zip',
        license=LicenseEnum.cc_by,
        platform=PlatformEnum.drone,
        authors=['Test Author'],
        token=auth_token,
    )
    
    assert dataset is not None
    assert isinstance(dataset, Dataset)

def test_exif_extraction_populates_acquisition_date(temp_test_zip, test_user, auth_token):
    """Test that EXIF extraction works with real data"""
    # Test real functionality without mocks
    dataset = await process_raw_images_upload(...)
    assert dataset is not None

@pytest.mark.parametrize('lat,lon', TEST_POINTS_WITH_DATA)
def test_phenology_with_real_coordinates(lat, lon):
    """Test phenology function with real geographic coordinates"""
    result = get_phenology_curve(lat, lon)
    if result is not None:
        assert len(result) == 365
        assert all(0 <= val <= 255 for val in result)
```

### **‚úÖ Business Logic: Functions Over Classes**
```python
# GOOD: Processing functions (existing codebase pattern)
def process_metadata(task: QueueTask, temp_dir: Path):
    """Process and store metadata for a dataset"""
    # Processing logic here
    pass

def process_cog(task: QueueTask, temp_dir: Path):
    """Process COG generation for a dataset"""
    # COG processing logic
    pass

def standardise_geotiff(input_path: str, output_path: str, token: str = None) -> bool:
    """Standardise a GeoTIFF file"""
    # Standardization logic
    return True

# GOOD: Utility functions
def get_biome_data(bbox_centroid) -> tuple:
    """Get biome data for coordinates"""
    return biome_name, biome_id

def extract_comprehensive_exif(image_path: Path) -> Dict[str, Any]:
    """Extract EXIF metadata from image"""
    return exif_dict

# BAD: Don't create classes for business logic
class MetadataProcessor:  # ‚ùå Avoid this pattern
    def process(self, task):
        pass

class BiomeExtractor:  # ‚ùå Avoid this pattern  
    def extract(self, coordinates):
        pass
```

### **‚úÖ When Classes ARE Appropriate**
```python
# GOOD: Data models (Pydantic models)
class Dataset(BaseModel):
    id: Optional[int] = None
    user_id: str
    file_name: str
    # ... other fields

class RawImages(BaseModel):
    id: Optional[int] = None
    dataset_id: int
    # ... other fields

# GOOD: Enums
class TaskTypeEnum(Enum):
    cog = 'cog'
    thumbnail = 'thumbnail'
    odm_processing = 'odm_processing'

# GOOD: Exception classes (when needed)
class ProcessingError(Exception):
    def __init__(self, message: str, task_type: str, **kwargs):
        self.task_type = task_type
        super().__init__(f'{task_type} processing failed: {message}')
```

## ‚ö° **ESSENTIAL COMMANDS**

### Environment Management
```bash
deadtrees dev start                    # Start development environment
deadtrees dev stop                     # Stop all containers
deadtrees dev start --force-rebuild   # Force rebuild containers (after dependency changes)
```

### Testing
```bash
deadtrees dev test api                 # Run API tests
deadtrees dev test processor           # Run processor tests
deadtrees dev test processor --test-path=processor/tests/utils/test_phenology.py  # Specific test file
deadtrees dev debug api               # Debug with breakpoints
deadtrees dev debug api --test-path=specific_test.py  # Debug specific test
```

### Environment Setup
```bash
supabase db reset                      # Reset database (always run before tests)
make download-assets                   # Download test data and geospatial assets
make symlinks                          # Create legacy symlinks
```

## üê≥ **CONTAINER SERVICES**
```yaml
# docker-compose.test.yaml services
api-test:         # Port 8017, Debug 5679
processor-test:   # Debug 5678, GPU support  
nginx:           # Port 8080, SSH 2222
```

**Debug Ports:**
- API: 5679
- Processor: 5678  
- CLI: 5680

## üß™ **TESTING PATTERNS**

### Test Execution
```bash
# Default (excludes slow tests)
deadtrees dev test api

# Include comprehensive tests
deadtrees dev test api --include-comprehensive

# Specific test categories
pytest -m comprehensive
pytest -m "slow and comprehensive"
```

### Real Data Testing (Preferred Pattern)
```python
# Use real geographic coordinates and datasets
TEST_POINTS_WITH_DATA = [
    # Black Forest, Germany (temperate forest)
    (48.0, 8.0),
    # Eastern Canada (temperate forest)  
    (45.0, -75.0),
    # Northern Michigan, USA (temperate forest)
    (45.8, -84.5),
    # Central Europe (temperate)
    (50.0, 10.0),
]

# Test points where no data should exist (ocean locations)
TEST_POINTS_NO_DATA = [
    # Atlantic Ocean
    (30.0, -30.0),
    # Pacific Ocean  
    (0.0, -150.0),
    # Southern Ocean
    (-30.0, 150.0),
]

@pytest.mark.parametrize('lat,lon', TEST_POINTS_WITH_DATA)
def test_utility_function_with_data(lat, lon):
    """Test utility function for locations with expected data."""
    result = get_data_for_location(lat, lon)
    
    if result is not None:  # Some locations might not have data
        assert isinstance(result, list)
        assert len(result) == EXPECTED_LENGTH
        assert all(isinstance(val, int) for val in result)
        assert all(0 <= val <= MAX_VALUE for val in result)
        # Should have some variation (not all same values)
        assert len(set(result)) > 1

@pytest.mark.parametrize('lat,lon', TEST_POINTS_NO_DATA)
def test_utility_function_no_data(lat, lon):
    """Test utility function for ocean locations (should return None)."""
    result = get_data_for_location(lat, lon)
    # Ocean locations should return None (no data)
    assert result is None
```

### Functional Test Structure (Required)
```python
@pytest.fixture
def sample_dataset():
    return Dataset(id=1, name="test_dataset")

@pytest.fixture
def metadata_task(test_dataset_for_processing, test_processor_user):
    """Create a metadata task for testing"""
    return QueueTask(
        id=1,
        dataset_id=test_dataset_for_processing,
        user_id=test_processor_user,
        task_types=[TaskTypeEnum.metadata],
        priority=1,
        is_processing=False,
        current_position=0,
    )

@pytest.mark.slow
def test_comprehensive_processing():
    """Marked as slow for optional execution"""
    pass

@pytest.mark.comprehensive  
def test_full_pipeline():
    """Comprehensive end-to-end test"""
    pass
```

### Integration Testing Pattern
```python
def test_metadata_processing_integration(metadata_task, auth_token):
    """Test that new metadata is properly integrated."""
    # Process metadata
    process_metadata(metadata_task, settings.processing_path)
    
    # Verify metadata was saved
    with use_client(auth_token) as client:
        response = client.table(settings.metadata_table).select('*').eq('dataset_id', metadata_task.dataset_id).execute()
        
    assert response.data
    metadata = response.data[0]['metadata']
    
    # Check if new metadata was included (conditional - depends on data availability)
    if MetadataType.NEW_TYPE in metadata:
        new_metadata = metadata[MetadataType.NEW_TYPE]
        assert 'data_field' in new_metadata
        assert len(new_metadata['data_field']) == EXPECTED_LENGTH
        assert new_metadata['source'] == 'Expected Source'
        assert new_metadata['version'] == '1.0'
```

### Authentication Testing
```python
def test_regular_user_operations():
    """Test with standard authenticated user"""
    user_token = login(TEST_USER_EMAIL, TEST_USER_PASSWORD)
    # Test with auth.uid() pattern
    
def test_processor_user_operations():
    """Test with processor user (email-based auth)"""
    processor_token = login(PROCESSOR_USERNAME, PROCESSOR_PASSWORD)
    # Test with auth.jwt() email pattern
```

## üö® **COMMON TEST FAILURES**

### Database Trigger Issues
```python
# Issue: auth.uid() returns NULL for processor user
# Solution: Check trigger handles dual authentication

def test_processor_trigger_handling():
    processor_token = login(PROCESSOR_USERNAME, PROCESSOR_PASSWORD)
    result = update_dataset_with_token(processor_token, dataset_id, changes)
    
    # Should not be empty - indicates trigger fired correctly
    history = get_edit_history(dataset_id) 
    assert len(history) > 0, "Processor user should trigger audit logging"
```

### Missing Dependencies After Rebuild
```bash
# If new dependencies added to requirements.txt
deadtrees dev start --force-rebuild  # Force rebuild to install new packages

# Check if scientific computing packages installed
docker-compose -f docker-compose.test.yaml exec processor-test python -c "import xarray, zarr, numpy; print('Dependencies OK')"
```

### Path Resolution Issues
```python
# Always use settings.base_path for asset paths
DATASET_PATH = settings.base_path / "assets" / "data" / "dataset.zarr"

# Not: hardcoded paths like Path("/app/assets/...")
```

### Container State Issues
```bash
# Reset test environment
deadtrees dev stop
deadtrees dev start

# Check logs
docker-compose -f docker-compose.test.yaml logs api-test
docker-compose -f docker-compose.test.yaml logs processor-test
```

## üîß **DEBUGGING WORKFLOWS**

### Failed Tests
```bash
# Get detailed output
deadtrees dev test api 2>&1 | tee test_output.log

# Debug specific test
deadtrees dev debug api --test-path=path/to/failing_test.py

# Connect to container
docker-compose -f docker-compose.test.yaml exec api-test bash
```

### Database State Debugging
```python
def debug_database_state():
    """Helper for debugging database issues during tests"""
    datasets = client.table('v2_datasets').select('*').execute()
    statuses = client.table('v2_statuses').select('*').execute()
    
    print(f"Datasets: {len(datasets.data)}")
    print(f"Statuses: {len(statuses.data)}")
    
    # Check for errors
    errors = client.table('v2_statuses').select('*').eq('has_error', True).execute()
    if errors.data:
        print(f"Datasets with errors: {[d['dataset_id'] for d in errors.data]}")
```

### Real Data Validation
```python
def test_real_data_accessibility():
    """Verify real datasets are accessible for testing"""
    dataset_path = settings.base_path / "assets" / "data" / "dataset.zarr"
    assert dataset_path.exists(), f"Test dataset not found at {dataset_path}"
    
    # Test data access
    import xarray as xr
    ds = xr.open_zarr(dataset_path)
    assert 'data_variable' in ds.variables, "Expected data variable not found"
```

## üìÅ **TEST DATA MANAGEMENT**
```
assets/
‚îú‚îÄ‚îÄ test_data/debugging/testcases/
‚îÇ   ‚îú‚îÄ‚îÄ small/          # Small test files for comprehensive testing
‚îÇ   ‚îî‚îÄ‚îÄ original/       # Original large test files
‚îú‚îÄ‚îÄ pheno/              # Phenology datasets
‚îÇ   ‚îî‚îÄ‚îÄ modispheno_aggregated_normalized.zarr/
‚îú‚îÄ‚îÄ gadm/               # GADM administrative boundaries
‚îî‚îÄ‚îÄ biom/               # Biome classification data
```

### Asset Commands
```bash
make download-assets    # Download required assets (GADM, biome, phenology data)
make symlinks          # Create legacy compatibility links  
make clean             # Clean downloaded assets
```

### Asset Verification
```bash
# Verify assets are downloaded correctly
ls -la assets/pheno/modispheno_aggregated_normalized.zarr/
ls -la assets/gadm/gadm_410.gpkg
ls -la assets/biom/terres_ecosystems.gpkg
```

## ‚ö†Ô∏è **ANTI-PATTERNS TO AVOID**

### ‚ùå Don't Use Test Classes
```python
# BAD: Test classes (never use these)
class TestZipUploadProcessing:
    def test_zip_upload_creates_dataset(self):
        pass
    
    def test_zip_upload_creates_raw_images_entry(self):
        pass

# GOOD: Use functions instead
def test_zip_upload_creates_dataset():
    """Test ZIP upload creates v2_datasets entry correctly"""
    pass

def test_zip_upload_creates_raw_images_entry():
    """Test ZIP upload creates v2_raw_images entry correctly"""
    pass
```

### ‚ùå Don't Create Classes for Business Logic
```python
# BAD: Classes for processing logic
class MetadataProcessor:
    def __init__(self, task, temp_dir):
        self.task = task
        self.temp_dir = temp_dir
    
    def process(self):
        # processing logic
        pass

# GOOD: Use functions instead
def process_metadata(task: QueueTask, temp_dir: Path):
    """Process and store metadata for a dataset"""
    # processing logic
    pass
```

### ‚ùå Don't Mock Geospatial Functions
```python
# BAD: Mocking geospatial data access
@patch('processor.src.utils.phenology.xr.open_zarr')
def test_phenology_with_mock(mock_open_zarr):
    mock_ds = MagicMock()
    mock_ds.sel.return_value.data.values = [1, 2, 3]
    # This doesn't test real coordinate transformation or data access
```

### ‚úÖ Do Use Real Data Testing
```python
# GOOD: Testing with real coordinates and datasets
def test_phenology_with_real_data():
    """Test phenology retrieval for Black Forest coordinates"""
    lat, lon = 48.0, 8.0  # Real coordinates
    result = get_phenology_curve(lat, lon)
    
    if result is not None:
        assert len(result) == 365
        assert all(0 <= val <= 255 for val in result)
```

### ‚ùå Don't Use Hardcoded Paths
```python
# BAD: Hardcoded paths
DATASET_PATH = Path("/app/assets/pheno/modispheno_aggregated_normalized.zarr")

# GOOD: Use settings
DATASET_PATH = settings.base_path / "assets" / "pheno" / "modispheno_aggregated_normalized.zarr"
```

### ‚ùå Don't Run pytest Directly
```bash
# BAD: Direct pytest
pytest processor/tests/

# GOOD: Use CLI
deadtrees dev test processor
```

## üéØ **BEST PRACTICES**
1. **Always reset database** before running tests (`supabase db reset`)
2. **Use CLI commands** for all development tasks
3. **Test both authentication patterns** (regular user + processor)
4. **Mark slow tests** with `@pytest.mark.slow`
5. **Clean up test data** after test runs
6. **Use real data testing** for geospatial and utility functions
7. **Force rebuild** after adding new dependencies
8. **Use parametrized tests** with real coordinates
9. **Test graceful degradation** for optional data sources
10. **Verify asset availability** before running tests that depend on external datasets
11. **NEVER use test classes** - always use functions
12. **PREFER functions over classes** throughout the codebase
13. **Use classes only for data models, enums, and exceptions**
